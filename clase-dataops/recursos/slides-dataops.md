# ğŸ“Š Slides: Clase DataOps
**Para presentaciÃ³n en clase**

---

## Slide 1: TÃ­tulo
# DataOps en Streaming de Criptomonedas
## AutomatizaciÃ³n, Testing y Monitoreo de Pipelines de Datos

**DuraciÃ³n:** 2 horas  
**Modalidad:** PrÃ¡ctica (70%) + TeorÃ­a (30%)

---

## Slide 2: Agenda
# ğŸ“‹ Agenda de la Clase

| Tiempo | Bloque | Contenido |
|--------|--------|-----------|
| **15 min** | Fundamentos | Â¿QuÃ© es DataOps? |
| **15 min** | DiseÃ±o | Arquitectura del Pipeline |
| **30 min** | AutomatizaciÃ³n | Setup en 1 comando |
| **30 min** | Testing | Calidad de datos |
| **20 min** | Monitoreo | Observabilidad |
| **10 min** | CI/CD | Pipeline automatizado |

---

## Slide 3: Problema
# ğŸš¨ El Problema Actual

## Sin DataOps:
- âŒ Setup manual de 30+ minutos
- âŒ Problemas detectados tarde
- âŒ Sin visibilidad del pipeline
- âŒ Deployments propensos a errores
- âŒ Calidad de datos inconsistente

## Impacto en el Negocio:
- ğŸ’° PÃ©rdidas por datos incorrectos
- â±ï¸ Tiempo perdido en troubleshooting
- ğŸ˜¤ FrustraciÃ³n del equipo

---

## Slide 4: SoluciÃ³n DataOps
# âœ… La SoluciÃ³n: DataOps

## Con DataOps:
- âœ… Setup automatizado en 5 minutos
- âœ… DetecciÃ³n proactiva de problemas
- âœ… Monitoreo en tiempo real
- âœ… CI/CD automatizado
- âœ… Calidad de datos garantizada

## Beneficios:
- ğŸ“ˆ 95% reducciÃ³n en tiempo de setup
- ğŸ¯ DetecciÃ³n automÃ¡tica de anomalÃ­as
- ğŸ“Š 100% visibilidad del pipeline

---

## Slide 5: Arquitectura Actual
# ğŸ—ï¸ Pipeline Actual (Sin DataOps)

```mermaid
graph LR
    A[CoinGecko API] --> B[Kafka Connect]
    B --> C[Kafka Topics]
    C --> D[Flink Processing]
    D --> E[Tableflow]
    E --> F[DuckDB]
```

## Puntos de Falla:
- ğŸš¨ API rate limiting
- ğŸš¨ ConfiguraciÃ³n incorrecta
- ğŸš¨ Errores de transformaciÃ³n
- ğŸš¨ Schema evolution

---

## Slide 6: Arquitectura DataOps
# ğŸ›¡ï¸ Pipeline con DataOps

```mermaid
graph TB
    subgraph "DataOps Layer"
        AUTO[Automation]
        TEST[Testing]
        MON[Monitoring]
        CICD[CI/CD]
    end
    
    subgraph "Data Pipeline"
        API[CoinGecko] --> KC[Kafka Connect]
        KC --> KT[Topics] --> FL[Flink]
        FL --> TF[Tableflow] --> DB[DuckDB]
    end
    
    AUTO --> KC
    TEST --> KT
    MON --> FL
    CICD --> AUTO
```

---

## Slide 7: Componentes DataOps
# ğŸ”§ Componentes Implementados

## 1. **AutomatizaciÃ³n**
```bash
./setup-pipeline.sh  # 1 comando = pipeline completo
```

## 2. **Testing**
```python
test_data_freshness()    # Datos < 5 min
test_price_validity()    # Rangos correctos
test_completeness()      # Sin campos vacÃ­os
```

## 3. **Monitoreo**
```python
throughput: 2.5 msg/sec
error_rate: 0%
data_quality: 95%
```

---

## Slide 8: Demo - Antes vs DespuÃ©s
# ğŸ¬ Demo: Manual vs Automatizado

## Proceso Manual (âŒ)
```bash
confluent login
confluent environment use env-xxxxx
confluent kafka cluster use lkc-xxxxx
confluent kafka topic create crypto-prices --partitions 3
confluent kafka topic create crypto-prices-exploded --partitions 3
confluent connect cluster create --config-file config.json
# ... 15+ pasos mÃ¡s
```

## Proceso Automatizado (âœ…)
```bash
./dataops/automation/setup-pipeline.sh
```

**Resultado:** 30 minutos â†’ 5 minutos

---

## Slide 9: Tests de Calidad
# ğŸ§ª Tests de Calidad de Datos

## Tests Implementados:
1. **Estructura:** Â¿Tiene todos los campos?
2. **Frescura:** Â¿Datos < 5 minutos?
3. **Validez:** Â¿Precios en rangos esperados?
4. **Completitud:** Â¿Sin valores nulos?

## Test Personalizado:
```python
def test_extreme_volatility(message):
    btc_change = message['bitcoin']['usd_24h_change']
    if abs(btc_change) > 15:  # Bitcoin cambiÃ³ >15%
        return FAIL("Extreme volatility detected")
    return PASS
```

---

## Slide 10: Monitoreo en Tiempo Real
# ğŸ“Š Monitoreo y Alertas

## MÃ©tricas Clave:
- **Throughput:** 2.5 mensajes/segundo
- **Latencia:** < 100ms end-to-end
- **Error Rate:** 0%
- **Data Quality Score:** 95%

## Alertas AutomÃ¡ticas:
```python
if bitcoin_price > 100000:
    alert("Bitcoin price spike!", severity="HIGH")

if data_age > 600:  # 10 minutos
    alert("Stale data detected", severity="MEDIUM")
```

---

## Slide 11: CI/CD Pipeline
# ğŸ”„ CI/CD Automatizado

## GitHub Actions Workflow:
```yaml
on: [push, pull_request]
jobs:
  test:
    - Schema validation
    - Data quality tests
    - Infrastructure validation
  
  deploy:
    - Automated deployment
    - Post-deployment validation
```

## Beneficios:
- âœ… Tests automÃ¡ticos en cada commit
- âœ… Deployment sin errores
- âœ… Rollback automÃ¡tico si falla

---

## Slide 12: Resultados
# ğŸ“ˆ Resultados Obtenidos

## MÃ©tricas de Ã‰xito:

| MÃ©trica | Antes | DespuÃ©s | Mejora |
|---------|-------|---------|--------|
| **Setup Time** | 30 min | 5 min | 83% â†“ |
| **Error Detection** | Manual | AutomÃ¡tico | 100% â†‘ |
| **Pipeline Visibility** | 20% | 100% | 400% â†‘ |
| **Deployment Success** | 70% | 95% | 36% â†‘ |

## ROI:
- ğŸ’° **Ahorro:** 25 min Ã— $50/hora = $20.83 por deployment
- ğŸ“Š **Calidad:** 95% success rate en tests
- âš¡ **Velocidad:** Deploy en segundos vs horas

---

## Slide 13: PrÃ¡ctica - Ejercicio 1
# ğŸ› ï¸ PRÃCTICA: Setup Automatizado

## Tu Turno:
1. **Clonar repositorio**
2. **Configurar .env**
3. **Ejecutar:** `./dataops/automation/setup-pipeline.sh`
4. **Validar:** Pipeline funcionando

## Tiempo: 15 minutos

### âœ… Resultado Esperado:
```
ğŸ‰ Pipeline setup completed successfully!
```

---

## Slide 14: PrÃ¡ctica - Ejercicio 2
# ğŸ§ª PRÃCTICA: Tests de Calidad

## Tu Turno:
1. **Ejecutar tests:** `python3 data-quality-tests.py`
2. **Analizar reporte:** `cat data-quality-report.json`
3. **Crear test personalizado**
4. **Validar success rate > 80%**

## Tiempo: 20 minutos

### âœ… Resultado Esperado:
```
ğŸ“Š Success Rate: 90.0%
```

---

## Slide 15: PrÃ¡ctica - Ejercicio 3
# ğŸ“Š PRÃCTICA: Monitoreo

## Tu Turno:
1. **Iniciar monitoreo:** `python3 pipeline-monitor.py`
2. **Observar mÃ©tricas en tiempo real**
3. **Configurar alerta personalizada**
4. **Generar reporte**

## Tiempo: 15 minutos

### âœ… Resultado Esperado:
```
ğŸ“ˆ Total Messages: 150
âš¡ Avg Throughput: 2.5 msg/sec
```

---

## Slide 16: Mejores PrÃ¡cticas
# ğŸ’¡ Mejores PrÃ¡cticas DataOps

## 1. **Automatiza Todo**
- Setup, testing, deployment, monitoreo

## 2. **Falla RÃ¡pido**
- Tests en cada etapa del pipeline

## 3. **Observabilidad First**
- MÃ©tricas, logs, alertas desde el dÃ­a 1

## 4. **ColaboraciÃ³n**
- Data Engineers + Data Scientists + DevOps

## 5. **IteraciÃ³n Continua**
- Mejora constante basada en mÃ©tricas

---

## Slide 17: PrÃ³ximos Pasos
# ğŸš€ PrÃ³ximos Pasos

## Nivel 2: Observabilidad Avanzada
- [ ] IntegraciÃ³n con Prometheus/Grafana
- [ ] Dashboards personalizados
- [ ] Alertas por Slack/Email

## Nivel 3: ML Ops
- [ ] DetecciÃ³n de anomalÃ­as con ML
- [ ] PredicciÃ³n de fallos
- [ ] Auto-scaling basado en mÃ©tricas

## Nivel 4: Data Governance
- [ ] Data lineage tracking
- [ ] Schema evolution management
- [ ] Compliance reporting

---

## Slide 18: Recursos
# ğŸ“š Recursos Adicionales

## DocumentaciÃ³n:
- [Confluent Cloud Docs](https://docs.confluent.io/cloud/)
- [Apache Kafka Docs](https://kafka.apache.org/documentation/)
- [DataOps Best Practices](https://www.dataops.org/)

## Herramientas:
- **Great Expectations:** Tests de calidad
- **Apache Airflow:** OrquestaciÃ³n
- **Prometheus + Grafana:** Monitoreo

## Comunidad:
- DataOps Community Slack
- Confluent Community Forum

---

## Slide 19: Q&A
# â“ Preguntas y Respuestas

## Preguntas Frecuentes:

**P:** Â¿CÃ³mo escalar DataOps a mÃºltiples pipelines?  
**R:** Usar templates y herramientas de orquestaciÃ³n como Airflow.

**P:** Â¿QuÃ© hacer si los tests fallan en producciÃ³n?  
**R:** Rollback automÃ¡tico + alertas + anÃ¡lisis de causa raÃ­z.

**P:** Â¿CÃ³mo medir ROI de DataOps?  
**R:** Tiempo ahorrado + reducciÃ³n de errores + mejora en calidad.

---

## Slide 20: Cierre
# ğŸ‰ Â¡Felicitaciones!

## Has Implementado:
- âœ… Pipeline DataOps completo
- âœ… AutomatizaciÃ³n end-to-end
- âœ… Tests de calidad personalizados
- âœ… Monitoreo en tiempo real
- âœ… CI/CD automatizado

## Impacto:
- ğŸš€ **83% reducciÃ³n** en tiempo de setup
- ğŸ“Š **100% visibilidad** del pipeline
- ğŸ¯ **DetecciÃ³n proactiva** de problemas

### Â¡Ahora eres un DataOps Engineer! ğŸš€