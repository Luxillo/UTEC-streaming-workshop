# ðŸ§ª Ejercicio 2: Tests de Calidad de Datos
**Tiempo estimado:** 20 minutos

## ðŸŽ¯ Objetivo
Implementar y personalizar tests de calidad de datos para el pipeline de streaming de criptomonedas.

## ðŸ“‹ Prerequisitos
- [ ] Pipeline funcionando (Ejercicio 1 completado)
- [ ] Python 3.8+ con confluent-kafka instalado
- [ ] Datos fluyendo en tÃ³picos

## ðŸ§ª Parte A: Ejecutar Tests Existentes (10 min)

### Paso 1: Instalar Dependencias
```bash
pip3 install confluent-kafka
```

### Paso 2: Configurar Variables de Entorno
```bash
cd scripts/kafka
source .env
export KAFKA_BOOTSTRAP_SERVERS="${KAFKA_BOOTSTRAP_SERVERS:-pkc-your-cluster.region.aws.confluent.cloud:9092}"
```

### Paso 3: Ejecutar Tests de Calidad
```bash
cd ../../dataops/tests
python3 data-quality-tests.py
```

### âœ… Resultado Esperado
```
ðŸ” Running data quality tests on topic: crypto-prices
â±ï¸  Timeout: 30 seconds
âœ… Tested message 1
âœ… Tested message 2
âœ… Tested message 3
ðŸ“Š Total messages tested: 3

==================================================
ðŸ“‹ DATA QUALITY REPORT
==================================================
âœ… Passed: 10
âŒ Failed: 2
ðŸ“Š Success Rate: 83.3%

ðŸ“„ Report saved to: data-quality-report.json
```

### Paso 4: Analizar Reporte
```bash
# Ver reporte detallado
cat data-quality-report.json | jq .
```

## ðŸ”§ Parte B: Crear Tests Personalizados (10 min)

### Test 1: ValidaciÃ³n de Volatilidad Extrema
Agrega este mÃ©todo a la clase `CryptoDataQualityTester`:

```python
def test_extreme_volatility(self, message: Dict[str, Any]) -> DataQualityResult:
    """Test personalizado: Detectar volatilidad extrema en 24h"""
    
    volatility_thresholds = {
        'bitcoin': 15.0,      # Bitcoin: mÃ¡ximo 15% cambio
        'ethereum': 20.0,     # Ethereum: mÃ¡ximo 20% cambio
        'solana': 25.0,       # Solana: mÃ¡ximo 25% cambio
        'cardano': 30.0,      # Cardano: mÃ¡ximo 30% cambio
        'binancecoin': 20.0   # BNB: mÃ¡ximo 20% cambio
    }
    
    for crypto, data in message.items():
        if isinstance(data, dict) and 'usd_24h_change' in data:
            change_pct = abs(data['usd_24h_change'])
            threshold = volatility_thresholds.get(crypto, 25.0)
            
            if change_pct > threshold:
                return DataQualityResult(
                    "extreme_volatility", False,
                    f"Extreme volatility in {crypto}: {change_pct}% (threshold: {threshold}%)", 
                    datetime.now()
                )
    
    return DataQualityResult(
        "extreme_volatility", True,
        "Volatility within acceptable ranges", 
        datetime.now()
    )
```

### Test 2: ValidaciÃ³n de Market Cap
```python
def test_market_cap_consistency(self, message: Dict[str, Any]) -> DataQualityResult:
    """Test personalizado: Validar consistencia de market cap"""
    
    for crypto, data in message.items():
        if isinstance(data, dict) and all(k in data for k in ['usd', 'usd_market_cap']):
            price = data['usd']
            market_cap = data['usd_market_cap']
            
            # Market cap debe ser mayor que el precio (obviamente)
            if market_cap < price:
                return DataQualityResult(
                    "market_cap_consistency", False,
                    f"Market cap ({market_cap}) less than price ({price}) for {crypto}", 
                    datetime.now()
                )
            
            # Market cap no puede ser 0 si hay precio
            if price > 0 and market_cap == 0:
                return DataQualityResult(
                    "market_cap_consistency", False,
                    f"Market cap is 0 but price is {price} for {crypto}", 
                    datetime.now()
                )
    
    return DataQualityResult(
        "market_cap_consistency", True,
        "Market cap data is consistent", 
        datetime.now()
    )
```

### Test 3: ValidaciÃ³n de CorrelaciÃ³n de Precios
```python
def test_price_correlation(self, message: Dict[str, Any]) -> DataQualityResult:
    """Test personalizado: Detectar precios anÃ³malos por correlaciÃ³n"""
    
    # Si Bitcoin sube/baja mucho, otras cryptos deberÃ­an seguir la tendencia
    if 'bitcoin' in message and 'ethereum' in message:
        btc_change = message['bitcoin'].get('usd_24h_change', 0)
        eth_change = message['ethereum'].get('usd_24h_change', 0)
        
        # Si Bitcoin cambia mÃ¡s de 10%, Ethereum deberÃ­a cambiar en la misma direcciÃ³n
        if abs(btc_change) > 10:
            if (btc_change > 0 and eth_change < -5) or (btc_change < 0 and eth_change > 5):
                return DataQualityResult(
                    "price_correlation", False,
                    f"Unusual correlation: BTC {btc_change}%, ETH {eth_change}%", 
                    datetime.now()
                )
    
    return DataQualityResult(
        "price_correlation", True,
        "Price correlations are normal", 
        datetime.now()
    )
```

### Integrar Tests Personalizados
Modifica el mÃ©todo `run_tests` para incluir los nuevos tests:

```python
# En el mÃ©todo run_tests, actualizar la lista de tests:
tests = [
    self.test_message_structure(message_data),
    self.test_data_freshness(message_data),
    self.test_price_validity(message_data),
    self.test_data_completeness(message_data),
    self.test_extreme_volatility(message_data),      # â† Nuevo
    self.test_market_cap_consistency(message_data),  # â† Nuevo
    self.test_price_correlation(message_data)        # â† Nuevo
]
```

### Ejecutar Tests Personalizados
```bash
python3 data-quality-tests.py
```

## ðŸ“Š Parte C: Automatizar Tests (5 min)

### Crear Script de EjecuciÃ³n
```bash
# Crear script automatizado
touch run-enhanced-tests.sh
```

**Contenido del script:**
```bash
#!/bin/bash
# Script para ejecutar tests de calidad mejorados

set -e

echo "ðŸ§ª Running Enhanced Data Quality Tests"
echo "====================================="

# Setup environment
cd ../../scripts/kafka
source .env
cd ../../dataops/tests

# Run tests multiple times for better coverage
for i in {1..3}; do
    echo "ðŸ”„ Test run $i/3"
    python3 data-quality-tests.py
    sleep 30  # Wait for more data
done

# Analyze results
echo "ðŸ“Š Analyzing test results..."
if [ -f "data-quality-report.json" ]; then
    SUCCESS_RATE=$(python3 -c "import json; report=json.load(open('data-quality-report.json')); print(report['summary']['success_rate'])")
    
    echo "ðŸ“ˆ Final Success Rate: $SUCCESS_RATE%"
    
    if (( $(echo "$SUCCESS_RATE >= 85" | bc -l) )); then
        echo "âœ… Data quality: EXCELLENT"
    elif (( $(echo "$SUCCESS_RATE >= 70" | bc -l) )); then
        echo "âš ï¸  Data quality: GOOD"
    else
        echo "âŒ Data quality: NEEDS IMPROVEMENT"
    fi
fi
```

### Ejecutar Tests Automatizados
```bash
chmod +x run-enhanced-tests.sh
./run-enhanced-tests.sh
```

## ðŸ“‹ ValidaciÃ³n y AnÃ¡lisis

### Analizar Patrones de Fallas
```bash
# Ver tests que fallan frecuentemente
cat data-quality-report.json | jq '.test_results[] | select(.status == "FAIL")'
```

### Crear Dashboard Simple
```python
# dashboard.py - Script simple para visualizar resultados
import json
import matplotlib.pyplot as plt

with open('data-quality-report.json', 'r') as f:
    report = json.load(f)

# GrÃ¡fico de success rate
tests = [r['test'] for r in report['test_results']]
statuses = [1 if r['status'] == 'PASS' else 0 for r in report['test_results']]

plt.figure(figsize=(12, 6))
plt.bar(tests, statuses, color=['green' if s else 'red' for s in statuses])
plt.title('Data Quality Test Results')
plt.ylabel('Pass (1) / Fail (0)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('test-results.png')
print("ðŸ“Š Dashboard saved as test-results.png")
```

## ðŸŽ¯ DesafÃ­os Adicionales

### DesafÃ­o 1: Test de Tendencias
Implementa un test que detecte si los precios estÃ¡n "congelados" (sin cambios por mÃ¡s de 10 minutos).

### DesafÃ­o 2: Test de Outliers
Crea un test que detecte precios que estÃ¡n mÃ¡s de 3 desviaciones estÃ¡ndar de la media histÃ³rica.

### DesafÃ­o 3: Test de API Health
Implementa un test que valide la salud de la API de CoinGecko basado en los tiempos de respuesta.

## âœ… Criterios de Ã‰xito

- [ ] Tests bÃ¡sicos ejecutan correctamente
- [ ] Success rate > 80%
- [ ] 3 tests personalizados implementados
- [ ] Tests automatizados funcionan
- [ ] Reportes se generan correctamente
- [ ] AnÃ¡lisis de resultados completado

## ðŸš¨ Troubleshooting

### Error: "No messages to test"
```bash
# Verificar que hay datos en el tÃ³pico
confluent kafka topic consume crypto-prices --from-beginning --max-messages 1
```

### Error: "JSON parsing failed"
```bash
# Verificar formato de mensajes
confluent kafka topic consume crypto-prices --from-beginning --max-messages 1 --print-key
```

### Tests fallan consistentemente
```bash
# Revisar logs detallados
python3 -c "
import logging
logging.basicConfig(level=logging.DEBUG)
exec(open('data-quality-tests.py').read())
"
```

---

**Siguiente:** [Ejercicio 3: Monitoreo](ejercicio-3-monitoreo.md)