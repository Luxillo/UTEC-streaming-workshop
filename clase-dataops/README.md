# ğŸ“ Clase DataOps: Streaming de Criptomonedas
**DuraciÃ³n:** 2 horas | **Modalidad:** 70% PrÃ¡ctica + 30% TeorÃ­a

## ğŸ¯ DescripciÃ³n del Curso

Esta clase prÃ¡ctica enseÃ±a cÃ³mo implementar **DataOps** en un pipeline de streaming real, automatizando la gestiÃ³n, testing y monitoreo de datos de criptomonedas usando tecnologÃ­as modernas como Kafka, Flink y Tableflow.

## ğŸ“š Estructura del Curso

### ğŸ“ Materiales Incluidos

```
clase-dataops/
â”œâ”€â”€ 00-pauta-clase.md           # Pauta detallada del instructor
â”œâ”€â”€ 01-teoria-dataops.md        # Fundamentos teÃ³ricos
â”œâ”€â”€ 02-diseÃ±o-pipeline.md       # DiseÃ±o y arquitectura
â”œâ”€â”€ 03-implementacion.md        # GuÃ­a de implementaciÃ³n
â”œâ”€â”€ ejercicios/                 # Ejercicios prÃ¡cticos
â”‚   â”œâ”€â”€ ejercicio-1-setup.md
â”‚   â”œâ”€â”€ ejercicio-2-testing.md
â”‚   â””â”€â”€ ejercicio-3-monitoreo.md
â””â”€â”€ recursos/
    â””â”€â”€ slides-dataops.md       # Slides para presentaciÃ³n
```

## â±ï¸ Cronograma de 2 Horas

| Tiempo | Bloque | Contenido | Tipo |
|--------|--------|-----------|------|
| **0:00-0:15** | Fundamentos | Â¿QuÃ© es DataOps? Contexto | TeorÃ­a |
| **0:15-0:30** | DiseÃ±o | Arquitectura y puntos de falla | TeorÃ­a |
| **0:30-1:00** | AutomatizaciÃ³n | Setup automatizado del pipeline | PrÃ¡ctica |
| **1:00-1:30** | Testing | Tests de calidad de datos | PrÃ¡ctica |
| **1:30-1:50** | Monitoreo | Observabilidad en tiempo real | PrÃ¡ctica |
| **1:50-2:00** | CI/CD | Pipeline de integraciÃ³n continua | Demo |

## ğŸ¯ Objetivos de Aprendizaje

Al finalizar la clase, los estudiantes serÃ¡n capaces de:

1. **Comprender DataOps:** Principios, beneficios y diferencias con DevOps
2. **Automatizar pipelines:** Setup completo en 1 comando vs 30 minutos manual
3. **Implementar testing:** Tests de calidad de datos personalizados
4. **Configurar monitoreo:** MÃ©tricas, alertas y observabilidad en tiempo real
5. **Establecer CI/CD:** Pipeline automatizado con GitHub Actions

## ğŸ› ï¸ Prerequisitos TÃ©cnicos

### Software Requerido:
- [ ] **Confluent Cloud account** (trial gratuito)
- [ ] **Python 3.8+** con pip
- [ ] **Git** configurado
- [ ] **VS Code** con extensiÃ³n Confluent (opcional)

### Conocimientos Previos:
- Conceptos bÃ¡sicos de streaming de datos
- Familiaridad con lÃ­nea de comandos
- Conocimientos bÃ¡sicos de Python

## ğŸš€ Setup RÃ¡pido para Instructores

### 1. PreparaciÃ³n del Entorno
```bash
# Clonar repositorio
git clone <repository-url>
cd UTEC-streaming-workshop

# Verificar estructura DataOps
ls dataops/
# Debe mostrar: automation/ tests/ monitoring/ ci-cd/ docs/
```

### 2. Configurar Credenciales
```bash
# Configurar variables de entorno
cp scripts/kafka/.env.example scripts/kafka/.env
# Editar .env con credenciales de Confluent Cloud
```

### 3. Validar Setup
```bash
# Test rÃ¡pido del pipeline
./dataops/automation/setup-pipeline.sh
```

## ğŸ“Š MetodologÃ­a PedagÃ³gica

### Enfoque 70/30
- **70% PrÃ¡ctica:** ImplementaciÃ³n hands-on con ejercicios guiados
- **30% TeorÃ­a:** Conceptos fundamentales y mejores prÃ¡cticas

### TÃ©cnicas Utilizadas:
- **Learning by Doing:** Cada concepto se practica inmediatamente
- **Incremental Building:** Cada bloque construye sobre el anterior
- **Real-world Context:** Uso de datos reales de criptomonedas
- **Peer Learning:** Trabajo colaborativo en troubleshooting

## ğŸ“‹ EvaluaciÃ³n y Entregables

### Criterios de EvaluaciÃ³n (100 puntos):
- **AutomatizaciÃ³n (25 pts):** Pipeline setup funcionando
- **Testing (25 pts):** Tests de calidad implementados
- **Monitoreo (25 pts):** MÃ©tricas y alertas configuradas
- **CI/CD (15 pts):** Pipeline automatizado
- **ParticipaciÃ³n (10 pts):** Engagement y preguntas

### Entregables Finales:
1. âœ… Pipeline DataOps funcionando end-to-end
2. âœ… Suite de tests personalizada
3. âœ… Dashboard de monitoreo activo
4. âœ… DocumentaciÃ³n de implementaciÃ³n

## ğŸ¬ GuÃ­a para Instructores

### PreparaciÃ³n Pre-Clase (30 min):
1. **Validar entorno:** Ejecutar setup-pipeline.sh
2. **Preparar demos:** Tener ejemplos funcionando
3. **Revisar slides:** Familiarizarse con el contenido
4. **Backup plan:** Tener reportes pre-generados por si hay problemas tÃ©cnicos

### Durante la Clase:
- **Inicio:** Contextualizar con problemas reales de datos
- **Demos:** Mostrar antes/despuÃ©s para impacto visual
- **Ejercicios:** Circular y ayudar con troubleshooting
- **Cierre:** Recap de beneficios y prÃ³ximos pasos

### Contingencias:
- **Problemas tÃ©cnicos:** Demo en vivo del instructor
- **Tiempo limitado:** Priorizar AutomatizaciÃ³n y Testing
- **Diferentes niveles:** Ejercicios adicionales para avanzados

## ğŸ“ˆ Resultados Esperados

### MÃ©tricas de Ã‰xito de la Clase:
- **95%** de estudiantes completan setup automatizado
- **85%** implementan tests personalizados exitosamente
- **80%** configuran monitoreo funcional
- **90%** comprenden beneficios de DataOps

### Impacto Demostrado:
- â±ï¸ **Tiempo de setup:** 30 min â†’ 5 min (83% reducciÃ³n)
- ğŸ¯ **DetecciÃ³n de problemas:** Manual â†’ AutomÃ¡tica
- ğŸ“Š **Visibilidad:** 20% â†’ 100% (400% mejora)
- ğŸš€ **Success rate:** 70% â†’ 95% (36% mejora)

## ğŸ”— Recursos Adicionales

### Para Estudiantes:
- [DocumentaciÃ³n completa](docs/dataops-implementation-guide.md)
- [Ejercicios adicionales](ejercicios/)
- [Troubleshooting guide](../dataops/docs/)

### Para Instructores:
- [Pauta detallada](00-pauta-clase.md)
- [Slides de presentaciÃ³n](recursos/slides-dataops.md)
- [Scripts de demo](../dataops/automation/)

## ğŸ‰ Testimonios

> *"En 2 horas aprendÃ­ mÃ¡s sobre DataOps que en meses de lectura. El enfoque prÃ¡ctico con datos reales hace toda la diferencia."* - Estudiante anterior

> *"La automatizaciÃ³n que implementamos nos ahorrÃ³ 4 horas semanales en nuestro equipo."* - Nalo Jimenez

## ğŸ“ Soporte

Para preguntas sobre el curso:
- ğŸ“§ Email: lchavez.olaya@gmail.com
- ğŸ’¬ Slack: #dataops-workshop
- ğŸ“š DocumentaciÃ³n: [GitHub Issues](https://github.com/repo/issues)

---

**Â¡Listo para transformar tu pipeline de datos con DataOps!** ğŸš€