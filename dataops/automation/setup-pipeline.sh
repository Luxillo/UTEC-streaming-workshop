#!/bin/bash

# üöÄ DataOps: Automated Pipeline Setup
# Automatiza el setup completo del pipeline de streaming

set -e

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
RESET='\033[0m'

echo -e "${BLUE}üöÄ DataOps: Automated Pipeline Setup${RESET}"
echo "========================================"

# 1. Validar prerequisitos
echo -e "${YELLOW}üìã Validating prerequisites...${RESET}"
if ! command -v confluent &> /dev/null; then
    echo -e "${RED}‚ùå Confluent CLI not found${RESET}"
    exit 1
fi

# 2. Setup environment
echo -e "${YELLOW}üîß Setting up environment...${RESET}"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
KAFKA_DIR="${SCRIPT_DIR}/../../scripts/kafka"

if [ ! -d "$KAFKA_DIR" ]; then
    echo -e "${RED}‚ùå Kafka scripts directory not found: $KAFKA_DIR${RESET}"
    exit 1
fi

cd "$KAFKA_DIR"
if [ ! -f ".env" ]; then
    echo -e "${RED}‚ùå .env file not found. Please configure your API keys${RESET}"
    exit 1
fi
source .env

# 3. Create topics
echo -e "${YELLOW}üìä Creating Kafka topics...${RESET}"
confluent kafka topic create crypto-prices --partitions 3 --config retention.ms=604800000 --config cleanup.policy=delete || true
confluent kafka topic create crypto-prices-exploded --partitions 3 --config retention.ms=604800000 --config cleanup.policy=delete || true

# 4. Deploy connector
echo -e "${YELLOW}üîå Deploying HTTP Source Connector...${RESET}"
./deploy-connector.sh

# 5. Validate setup
echo -e "${YELLOW}‚úÖ Validating setup...${RESET}"
./validate-connector.sh

echo -e "${GREEN}üéâ Pipeline setup completed successfully!${RESET}"
echo -e "${BLUE}üí° Next steps:${RESET}"
echo -e "   1. Run data quality tests: ./dataops/tests/run-data-quality-tests.sh"
echo -e "   2. Start monitoring: ./dataops/monitoring/start-monitoring.sh"