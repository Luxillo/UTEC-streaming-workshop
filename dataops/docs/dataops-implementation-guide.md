# DataOps Implementation Guide

## üéØ Objetivo

Esta gu√≠a implementa pr√°cticas de DataOps en el workshop de streaming de criptomonedas, automatizando la gesti√≥n, testing y monitoreo del pipeline de datos.

## üèóÔ∏è Arquitectura DataOps

```mermaid
graph TB
    subgraph "Source Control"
        GH[GitHub Repository]
        PR[Pull Requests]
    end
    
    subgraph "CI/CD Pipeline"
        GHA[GitHub Actions]
        SV[Schema Validation]
        DQT[Data Quality Tests]
        IV[Infrastructure Validation]
    end
    
    subgraph "Data Pipeline"
        KC[Kafka Connect]
        KT[Kafka Topics]
        FL[Flink Processing]
        TF[Tableflow]
    end
    
    subgraph "Monitoring & Observability"
        PM[Pipeline Monitor]
        DQM[Data Quality Metrics]
        AL[Alerts]
        RP[Reports]
    end
    
    GH --> GHA
    PR --> SV
    SV --> DQT
    DQT --> IV
    IV --> KC
    KC --> KT
    KT --> FL
    FL --> TF
    
    PM --> DQM
    DQM --> AL
    AL --> RP
    
    style DQT fill:#e1f5fe
    style PM fill:#f3e5f5
    style AL fill:#fff3e0
```

## üöÄ Componentes Implementados

### 1. Automatizaci√≥n (`automation/`)

**`setup-pipeline.sh`**
- Setup completo automatizado del pipeline
- Validaci√≥n de prerequisitos
- Creaci√≥n de t√≥picos
- Deployment de conectores
- Validaci√≥n end-to-end

### 2. Testing (`tests/`)

**`data-quality-tests.py`**
- Tests de estructura de mensajes
- Validaci√≥n de frescura de datos
- Verificaci√≥n de rangos de precios
- Tests de completitud de datos

**Tests implementados:**
- ‚úÖ Estructura del mensaje (campos requeridos)
- ‚úÖ Frescura de datos (< 5 minutos)
- ‚úÖ Validez de precios (rangos esperados)
- ‚úÖ Completitud de datos (sin valores nulos)

### 3. Monitoreo (`monitoring/`)

**`pipeline-monitor.py`**
- Monitoreo en tiempo real
- M√©tricas de throughput
- Detecci√≥n de anomal√≠as
- Alertas autom√°ticas

**M√©tricas monitoreadas:**
- üìä Throughput (mensajes/segundo)
- üìè Tama√±o promedio de mensajes
- ‚ö†Ô∏è Conteo de errores
- üïê Lag de consumidores

### 4. CI/CD (`ci-cd/`)

**`github-actions.yml`**
- Pipeline automatizado de CI/CD
- Validaci√≥n de esquemas Avro
- Tests de calidad de datos
- Deployment automatizado

**Jobs implementados:**
- üîç Schema Validation
- üß™ Data Quality Tests
- üèóÔ∏è Infrastructure Validation
- üìä Monitoring Setup
- üöÄ Deployment
- üì¢ Notifications

## üìã Gu√≠a de Uso

### Setup Inicial

```bash
# 1. Clonar el repositorio
git clone <repository-url>
cd UTEC-streaming-workshop

# 2. Configurar variables de entorno
cp scripts/kafka/.env.example scripts/kafka/.env
# Editar .env con tus credenciales

# 3. Ejecutar setup automatizado
chmod +x dataops/automation/setup-pipeline.sh
./dataops/automation/setup-pipeline.sh
```

### Ejecutar Tests de Calidad

```bash
# Tests manuales
chmod +x dataops/tests/run-data-quality-tests.sh
./dataops/tests/run-data-quality-tests.sh

# Ver reporte
cat dataops/tests/data-quality-report.json
```

### Iniciar Monitoreo

```bash
# Monitoreo en tiempo real
cd dataops/monitoring
python3 pipeline-monitor.py

# Ver logs
tail -f pipeline-monitor.log
```

### CI/CD Setup

```bash
# 1. Copiar workflow a .github/workflows/
mkdir -p .github/workflows
cp dataops/ci-cd/github-actions.yml .github/workflows/

# 2. Configurar secrets en GitHub:
# - KAFKA_BOOTSTRAP_SERVERS
# - KAFKA_API_KEY  
# - KAFKA_API_SECRET

# 3. Push para activar pipeline
git add .
git commit -m "Add DataOps implementation"
git push origin main
```

## üîß Configuraci√≥n Avanzada

### Personalizar Tests de Calidad

Editar `dataops/tests/data-quality-tests.py`:

```python
# Agregar nuevo test
def test_custom_validation(self, message: Dict[str, Any]) -> DataQualityResult:
    # Tu l√≥gica de validaci√≥n personalizada
    pass
```

### Configurar Alertas

Editar `dataops/monitoring/pipeline-monitor.py`:

```python
# Personalizar umbrales de alertas
def check_data_quality_alerts(self):
    # Tus reglas de alertas personalizadas
    pass
```

### Extender CI/CD

Agregar jobs en `dataops/ci-cd/github-actions.yml`:

```yaml
custom-validation:
  runs-on: ubuntu-latest
  steps:
    - name: Custom Validation
      run: |
        # Tu validaci√≥n personalizada
```

## üìä M√©tricas y KPIs

### Data Quality KPIs
- **Success Rate**: % de tests que pasan
- **Data Freshness**: Tiempo desde √∫ltima actualizaci√≥n
- **Completeness**: % de campos completos
- **Validity**: % de datos dentro de rangos esperados

### Pipeline KPIs
- **Throughput**: Mensajes procesados por segundo
- **Latency**: Tiempo de procesamiento end-to-end
- **Error Rate**: % de mensajes con errores
- **Availability**: % de uptime del pipeline

### Monitoring KPIs
- **Alert Response Time**: Tiempo hasta detecci√≥n de problemas
- **MTTR**: Tiempo promedio de recuperaci√≥n
- **SLA Compliance**: % de cumplimiento de SLAs

## üö® Troubleshooting

### Tests de Calidad Fallan

```bash
# Verificar conectividad
curl -s "https://api.coingecko.com/api/v3/simple/price?ids=bitcoin&vs_currencies=usd"

# Verificar configuraci√≥n Kafka
confluent kafka topic list

# Revisar logs
tail -f dataops/tests/data-quality-report.json
```

### Monitoreo No Funciona

```bash
# Verificar dependencias
pip3 install confluent-kafka

# Verificar variables de entorno
echo $KAFKA_BOOTSTRAP_SERVERS

# Revisar logs de monitoreo
tail -f dataops/monitoring/pipeline-monitor.log
```

### CI/CD Pipeline Falla

```bash
# Verificar secrets en GitHub
# Settings > Secrets and variables > Actions

# Verificar sintaxis YAML
yamllint .github/workflows/github-actions.yml

# Revisar logs en GitHub Actions
```

## üîÑ Mejoras Futuras

### Fase 2: Observabilidad Avanzada
- [ ] Integraci√≥n con Prometheus/Grafana
- [ ] Dashboards personalizados
- [ ] Alertas por Slack/Email

### Fase 3: ML Ops
- [ ] Detecci√≥n de anomal√≠as con ML
- [ ] Predicci√≥n de fallos
- [ ] Auto-scaling basado en m√©tricas

### Fase 4: Governance
- [ ] Data lineage tracking
- [ ] Schema evolution management
- [ ] Compliance reporting

## üìö Referencias

- [Confluent Cloud Documentation](https://docs.confluent.io/cloud/current/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [DataOps Best Practices](https://www.dataops.org/)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)