= Pr√°ctica con Confluent Cloud: Apache Kafka¬Æ, Apache Flink¬Æ y Tableflow
Viktor Gamov <vgamov@confluent.io>, ¬© 2025 Confluent, Inc.
2025-09-11
:revdate: 2025-09-11 23:52:23 -0600
:linkattrs:
:ast: &ast;
:y: &#10003;
:n: &#10008;
:y: icon:check-sign[role="green"]
:n: icon:check-minus[role="red"]
:c: icon:file-text-alt[role="blue"]
:toc: auto
:toc-placement: auto
:toc-position: auto
:toc-title: Tabla de contenido
:toclevels: 3
:idprefix:
:idseparator: -
:sectanchors:
:icons: font
:source-highlighter: highlight.js
:highlightjs-theme: idea
:experimental:

Confluent Cloud es una plataforma totalmente administrada para Apache Kafka, dise√±ada para simplificar la transmisi√≥n y el procesamiento de datos en tiempo real.
Integra Kafka para la ingesta de datos, Flink para el procesamiento de transmisiones y Tableflow para convertir datos de transmisi√≥n en tablas Apache Iceberg listas para an√°lisis.
DuckDB, una base de datos anal√≠tica ligera, permite consultar estas tablas Iceberg, lo que la convierte en una herramienta ideal para el componente de an√°lisis del taller. El taller est√° dise√±ado para desarrolladores con conocimientos b√°sicos de programaci√≥n, posiblemente nuevos en Kafka, Flink o Tableflow, y busca brindar experiencia pr√°ctica en un plazo breve.

[IMPORTANTE]
====
üö® **IMPORTANTE CR√çTICO - PREVENCI√ìN DE COSTOS**: Despu√©s de completar este taller, **siga inmediatamente la gu√≠a de desmontaje** para evitar cargos inesperados de los pools de c√≥mputo de Flink y las integraciones del cat√°logo de Tableflow.

üìã **Gu√≠a de desmontaje**: `guides/05-teardown-resources.adoc`

**Ejecute los pasos de desmontaje dentro de los 15 minutos posteriores a la finalizaci√≥n del taller** para evitar la facturaci√≥n continua de los recursos en la nube.
====

toc::[]

== Resumen del taller

Este taller pr√°ctico de 2.5 horas introduce a los desarrolladores  y arquitectos a los conceptos y procesos de creaci√≥n de pipelines de datos en tiempo real con Confluent Cloud.

Aprender√°s a transmitir datos con Apache Kafka, procesarlos en tiempo real con Apache Flink y convertirlos en tablas Apache Iceberg usando Tableflow.
El taller presupone conocimientos b√°sicos de programaci√≥n y ofrece una gu√≠a paso a paso a traves de ormatos legible y comandos reproducibles.

== Qu√© aprender√°s

* Configurar un cl√∫ster de Kafka y gestionar temas en Confluent Cloud.
* Escribir y ejecutar un trabajo de Flink para procesar datos en streaming.
* Usar Tableflow para materializar temas de Kafka como tablas Iceberg y consultarlos con DuckDB.

== Requisitos previos

* *Cuenta de GitHub*: Necesaria para acceder a GitHub Codespaces y/o clonar el repositorio del taller.
** https://github.com/join[Crea una cuenta gratuita de GitHub] si no tienes una
* *VSCode con extensi√≥n de Confluent*: Para gestionar recursos de Confluent Cloud. ** https://docs.confluent.io/cloud/current/client-apps/vs-code-extension.html[https://docs.confluent.io/cloud/current/client-apps/vs-code-extension.html]
* *Confluent CLI*: Para interactuar con cl√∫steres y temas de Kafka.
** https://docs.confluent.io/confluent-cli/current/install.html[https://docs.confluent.io/confluent-cli/current/install.html]
* *DuckDB*: Para consultar tablas Iceberg de Tableflow.
** https://duckdb.org/docs/installation/[https://duckdb.org/docs/installation/]

[NOTA]
====
üñ•Ô∏è **Compatibilidad con plataformas**: Todos los scripts del taller est√°n dise√±ados para Linux y macOS (con shell zsh).

üíª **Usuarios de Windows**: Recomendamos usar GitHub Codespaces o VS Code Dev Containers para una mejor experiencia. La configuraci√≥n de DevContainer proporciona un entorno Linux consistente con todas las herramientas preinstaladas.

üöÄ **Opciones de inicio r√°pido**:
* **GitHub Codespaces** (Recomendado para Windows): Haz clic en "C√≥digo" ‚Üí "Codespaces" ‚Üí "Crear codespace"
* **Contenedores de desarrollo**: Abrir en VS Code ‚Üí Ctrl+Shift+P ‚Üí "Contenedores de desarrollo: Reabrir en el contenedor"
* **Configuraci√≥n local**: Los usuarios de Linux/MacOS pueden ejecutar scripts directamente
====

=== Segmentos del taller y caracter√≠sticas cubiertas

|===
|*Segmento*|*Duraci√≥n*|*Caracter√≠sticas cubiertas*|*Objetivo*

|Introducci√≥n|20 min|Descripci√≥n general de Kafka, Flink y Tableflow|Comprender la arquitectura basada en eventos
|Configuraci√≥n de Confluent Cloud|25 min|Creaci√≥n de cl√∫steres de Kafka|Configurar un cl√∫ster de Kafka administrado via CLI
|Pr√°ctica con Kafka|30 min|Kafka Temas, Productores, Consumidores | Transmite datos con Kafka
|Flink Pr√°ctica | 45 min | Procesamiento de flujos de Flink | Procesa datos en tiempo real
|Tableflow Pr√°ctica | 30 min | Tableflow, Iceberg, DuckDB | Materializa y consulta datos listos para an√°lisis
|Resumen y preguntas y respuestas | 15 min | Todas las funciones | Resumen y respuestas
|===